{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f70d96e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'bibtexparser' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'bibtexparser'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  DEPRECATION: Building 'free-proxy' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'free-proxy'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  DEPRECATION: Building 'sgmllib3k' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'sgmllib3k'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: crewai in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (0.150.0)\n",
      "Requirement already satisfied: crewai-tools in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (0.58.0)\n",
      "Requirement already satisfied: gradio in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (5.38.2)\n",
      "Requirement already satisfied: openai in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (1.97.1)\n",
      "Collecting arxiv\n",
      "  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting scholarly\n",
      "  Downloading scholarly-1.7.11-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (4.13.4)\n",
      "Requirement already satisfied: requests in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (2.32.4)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (1.4.4)\n",
      "Requirement already satisfied: blinker>=1.9.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (1.9.0)\n",
      "Requirement already satisfied: chromadb>=0.5.23 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (0.5.23)\n",
      "Requirement already satisfied: click>=8.1.7 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (8.2.1)\n",
      "Requirement already satisfied: instructor>=1.3.3 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (1.10.0)\n",
      "Requirement already satisfied: json-repair==0.25.2 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (0.25.2)\n",
      "Requirement already satisfied: json5>=0.10.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (0.12.0)\n",
      "Requirement already satisfied: jsonref>=1.1.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (1.1.0)\n",
      "Requirement already satisfied: litellm==1.74.3 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (1.74.3)\n",
      "Requirement already satisfied: onnxruntime==1.22.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (1.22.0)\n",
      "Requirement already satisfied: openpyxl>=3.1.5 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (3.1.5)\n",
      "Requirement already satisfied: opentelemetry-api>=1.30.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.30.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.30.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (1.35.0)\n",
      "Requirement already satisfied: pdfplumber>=0.11.4 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (0.11.7)\n",
      "Requirement already satisfied: portalocker==2.7.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (2.7.0)\n",
      "Requirement already satisfied: pydantic>=2.4.2 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (2.11.7)\n",
      "Requirement already satisfied: pyjwt>=2.9.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (2.10.1)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (1.1.1)\n",
      "Requirement already satisfied: pyvis>=0.3.2 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (0.3.2)\n",
      "Requirement already satisfied: regex>=2024.9.11 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers>=0.20.3 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (0.20.3)\n",
      "Requirement already satisfied: tomli-w>=1.1.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (1.2.0)\n",
      "Requirement already satisfied: tomli>=2.0.2 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (2.2.1)\n",
      "Requirement already satisfied: uv>=0.4.25 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai) (0.8.3)\n",
      "Requirement already satisfied: aiohttp>=3.10 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from litellm==1.74.3->crewai) (3.12.14)\n",
      "Requirement already satisfied: httpx>=0.23.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from litellm==1.74.3->crewai) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from litellm==1.74.3->crewai) (8.7.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from litellm==1.74.3->crewai) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from litellm==1.74.3->crewai) (4.24.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from litellm==1.74.3->crewai) (0.9.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime==1.22.0->crewai) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime==1.22.0->crewai) (25.2.10)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime==1.22.0->crewai) (2.1.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime==1.22.0->crewai) (25.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime==1.22.0->crewai) (5.29.5)\n",
      "Requirement already satisfied: sympy in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime==1.22.0->crewai) (1.14.0)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from portalocker==2.7.0->crewai) (310)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.74.3->crewai) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.3->crewai) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.3->crewai) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.3->crewai) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.3->crewai) (0.26.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=2.4.2->crewai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=2.4.2->crewai) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=2.4.2->crewai) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=2.4.2->crewai) (0.4.1)\n",
      "Requirement already satisfied: docker>=7.1.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai-tools) (7.1.0)\n",
      "Requirement already satisfied: embedchain>=0.1.114 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai-tools) (0.1.128)\n",
      "Requirement already satisfied: lancedb>=0.5.4 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai-tools) (0.24.2)\n",
      "Requirement already satisfied: pyright>=1.1.350 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai-tools) (1.1.403)\n",
      "Requirement already satisfied: pytube>=15.0.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai-tools) (15.0.0)\n",
      "Requirement already satisfied: stagehand>=0.4.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from crewai-tools) (0.5.0)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (0.116.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (0.35.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (3.25.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (0.56b0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (33.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (9.1.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (3.11.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.5.23->crewai) (13.9.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from tokenizers>=0.20.3->crewai) (0.34.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.20.3->crewai) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.20.3->crewai) (2025.7.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (1.1.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.6.1)\n",
      "Requirement already satisfied: gradio-client==1.11.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (1.11.0)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (2.3.1)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (11.3.0)\n",
      "Requirement already satisfied: pydub in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.12.5)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.47.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.23.0->litellm==1.74.3->crewai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.23.0->litellm==1.74.3->crewai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx>=0.23.0->litellm==1.74.3->crewai) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from typer>=0.9.0->chromadb>=0.5.23->crewai) (1.5.4)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from openai) (0.10.0)\n",
      "Collecting feedparser~=6.0.10 (from arxiv)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from requests) (2.5.0)\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: arrow in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from scholarly) (1.3.0)\n",
      "Collecting bibtexparser (from scholarly)\n",
      "  Downloading bibtexparser-1.4.3.tar.gz (55 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting deprecated (from scholarly)\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting fake-useragent (from scholarly)\n",
      "  Downloading fake_useragent-2.2.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting free-proxy (from scholarly)\n",
      "  Downloading free_proxy-1.1.3.tar.gz (5.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting selenium (from scholarly)\n",
      "  Using cached selenium-4.34.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting sphinx-rtd-theme (from scholarly)\n",
      "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp>=3.10->litellm==1.74.3->crewai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp>=3.10->litellm==1.74.3->crewai) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp>=3.10->litellm==1.74.3->crewai) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp>=3.10->litellm==1.74.3->crewai) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp>=3.10->litellm==1.74.3->crewai) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp>=3.10->litellm==1.74.3->crewai) (1.20.1)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from build>=1.0.3->chromadb>=0.5.23->crewai) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from build>=1.0.3->chromadb>=0.5.23->crewai) (0.4.6)\n",
      "Requirement already satisfied: alembic<2.0.0,>=1.13.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from embedchain>=0.1.114->crewai-tools) (1.16.4)\n",
      "Requirement already satisfied: gptcache<0.2.0,>=0.1.43 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from embedchain>=0.1.114->crewai-tools) (0.1.44)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from embedchain>=0.1.114->crewai-tools) (0.3.27)\n",
      "Requirement already satisfied: langchain-cohere<0.4.0,>=0.3.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from embedchain>=0.1.114->crewai-tools) (0.3.5)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from embedchain>=0.1.114->crewai-tools) (0.3.27)\n",
      "Requirement already satisfied: langchain-openai<0.3.0,>=0.2.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from embedchain>=0.1.114->crewai-tools) (0.2.14)\n",
      "Requirement already satisfied: langsmith<0.4.0,>=0.3.18 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from embedchain>=0.1.114->crewai-tools) (0.3.45)\n",
      "Requirement already satisfied: mem0ai<0.2.0,>=0.1.54 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from embedchain>=0.1.114->crewai-tools) (0.1.115)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.0.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from embedchain>=0.1.114->crewai-tools) (5.9.0)\n",
      "Requirement already satisfied: pysbd<0.4.0,>=0.3.4 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from embedchain>=0.1.114->crewai-tools) (0.3.4)\n",
      "Requirement already satisfied: schema<0.8.0,>=0.7.5 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from embedchain>=0.1.114->crewai-tools) (0.7.7)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.27 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from embedchain>=0.1.114->crewai-tools) (2.0.41)\n",
      "Requirement already satisfied: Mako in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from alembic<2.0.0,>=1.13.1->embedchain>=0.1.114->crewai-tools) (1.3.10)\n",
      "Requirement already satisfied: cachetools in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from gptcache<0.2.0,>=0.1.43->embedchain>=0.1.114->crewai-tools) (5.5.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.3.72)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.3.9)\n",
      "Requirement already satisfied: cohere<6.0,>=5.5.6 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (5.16.1)\n",
      "Requirement already satisfied: langchain-experimental<0.4.0,>=0.3.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (0.3.4)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (0.9.0)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (1.11.1)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (0.4.0)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (2.32.4.20250611)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (2.10.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4.0,>=0.3.18->embedchain>=0.1.114->crewai-tools) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4.0,>=0.3.18->embedchain>=0.1.114->crewai-tools) (0.23.0)\n",
      "Requirement already satisfied: qdrant-client>=1.9.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (1.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from posthog>=2.4.0->chromadb>=0.5.23->crewai) (1.17.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from posthog>=2.4.0->chromadb>=0.5.23->crewai) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from posthog>=2.4.0->chromadb>=0.5.23->crewai) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->chromadb>=0.5.23->crewai) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->chromadb>=0.5.23->crewai) (2.19.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from sqlalchemy<3.0.0,>=2.0.27->embedchain>=0.1.114->crewai-tools) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (1.1.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from importlib-metadata>=6.8.0->litellm==1.74.3->crewai) (3.23.0)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from instructor>=1.3.3->crewai) (5.6.3)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.16 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from instructor>=1.3.3->crewai) (0.17.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (3.3.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (0.10)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (0.6.1)\n",
      "Requirement already satisfied: deprecation in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from lancedb>=0.5.4->crewai-tools) (2.1.0)\n",
      "Requirement already satisfied: pyarrow>=16 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from lancedb>=0.5.4->crewai-tools) (21.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.23->crewai) (0.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from openpyxl>=3.1.5->crewai) (2.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.23->crewai) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.35.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.23->crewai) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.35.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.23->crewai) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.56b0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-sdk>=1.30.0->crewai) (0.56b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.56b0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai) (0.56b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.56b0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai) (0.56b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.56b0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai) (0.56b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-instrumentation==0.56b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-instrumentation-asgi==0.56b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai) (3.9.1)\n",
      "Requirement already satisfied: pdfminer.six==20250506 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from pdfplumber>=0.11.4->crewai) (20250506)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from pdfplumber>=0.11.4->crewai) (4.30.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from pdfminer.six==20250506->pdfplumber>=0.11.4->crewai) (45.0.5)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber>=0.11.4->crewai) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber>=0.11.4->crewai) (2.22)\n",
      "Requirement already satisfied: nodeenv>=1.6.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from pyright>=1.1.350->crewai-tools) (1.9.1)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from pyvis>=0.3.2->crewai) (9.4.0)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from pyvis>=0.3.2->crewai) (4.1.1)\n",
      "Requirement already satisfied: networkx>=1.11 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from pyvis>=0.3.2->crewai) (3.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.51)\n",
      "Requirement already satisfied: stack_data in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.8.4)\n",
      "Requirement already satisfied: h2<5,>=3 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (4.2.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (4.1.0)\n",
      "Requirement already satisfied: playwright>=1.42.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from stagehand>=0.4.1->crewai-tools) (1.54.0)\n",
      "Requirement already satisfied: browserbase>=1.4.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from stagehand>=0.4.1->crewai-tools) (1.4.0)\n",
      "Requirement already satisfied: anthropic>=0.51.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from stagehand>=0.4.1->crewai-tools) (0.60.0)\n",
      "Requirement already satisfied: pyee<14,>=13 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from playwright>=1.42.1->stagehand>=0.4.1->crewai-tools) (13.0.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (1.1.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from arrow->scholarly) (2.9.0.20250708)\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from bibtexparser->scholarly) (3.2.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from coloredlogs->onnxruntime==1.22.0->crewai) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime==1.22.0->crewai) (3.5.4)\n",
      "Collecting lxml (from free-proxy->scholarly)\n",
      "  Downloading lxml-6.0.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->scholarly)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting trio~=0.30.0 (from selenium->scholarly)\n",
      "  Using cached trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.12.2 (from selenium->scholarly)\n",
      "  Using cached trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting sortedcontainers (from trio~=0.30.0->selenium->scholarly)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.30.0->selenium->scholarly)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium->scholarly)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting sphinx<9,>=6 (from sphinx-rtd-theme->scholarly)\n",
      "  Downloading sphinx-8.2.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting docutils<0.22,>0.18 (from sphinx-rtd-theme->scholarly)\n",
      "  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->scholarly)\n",
      "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sphinxcontrib-applehelp>=1.0.7 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-devhelp>=1.0.6 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.6 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-jsmath>=1.0.1 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting sphinxcontrib-qthelp>=1.0.6 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting snowballstemmer>=2.2 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading snowballstemmer-3.0.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: babel>=2.13 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (2.17.0)\n",
      "Collecting alabaster>=0.7.14 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading alabaster-1.0.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting imagesize>=1.3 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading imagesize-1.4.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting roman-numerals-py>=1.0.0 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading roman_numerals_py-3.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\soumi\\appdata\\roaming\\python\\python312\\site-packages (from sympy->onnxruntime==1.22.0->crewai) (1.3.0)\n",
      "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Downloading scholarly-1.7.11-py3-none-any.whl (39 kB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading fake_useragent-2.2.0-py3-none-any.whl (161 kB)\n",
      "Downloading lxml-6.0.0-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.0 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 1.3/4.0 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.1/4.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.9/4.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.7/4.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 3.9 MB/s eta 0:00:00\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached selenium-4.34.2-py3-none-any.whl (9.4 MB)\n",
      "Using cached trio-0.30.0-py3-none-any.whl (499 kB)\n",
      "Using cached trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
      "   ---------------------------------------- 0.0/7.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.8/7.7 MB 4.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.6/7.7 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.4/7.7 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.1/7.7 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.9/7.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.7/7.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.5/7.7 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.3/7.7 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.3/7.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.7/7.7 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading docutils-0.21.2-py3-none-any.whl (587 kB)\n",
      "   ---------------------------------------- 0.0/587.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 587.4/587.4 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading sphinx-8.2.3-py3-none-any.whl (3.6 MB)\n",
      "   ---------------------------------------- 0.0/3.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.8/3.6 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.6/3.6 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.4/3.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.1/3.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.6/3.6 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
      "Downloading alabaster-1.0.0-py3-none-any.whl (13 kB)\n",
      "Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Downloading roman_numerals_py-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading snowballstemmer-3.0.1-py3-none-any.whl (103 kB)\n",
      "Downloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl (119 kB)\n",
      "Downloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl (82 kB)\n",
      "Downloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl (98 kB)\n",
      "Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl (88 kB)\n",
      "Downloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl (92 kB)\n",
      "Building wheels for collected packages: bibtexparser, free-proxy, sgmllib3k\n",
      "  Building wheel for bibtexparser (setup.py): started\n",
      "  Building wheel for bibtexparser (setup.py): finished with status 'done'\n",
      "  Created wheel for bibtexparser: filename=bibtexparser-1.4.3-py3-none-any.whl size=43650 sha256=9574c9dda31cfae82a08ce95e74b686be3894121a0768a5ca51cc9faf69daff9\n",
      "  Stored in directory: c:\\users\\soumi\\appdata\\local\\pip\\cache\\wheels\\1f\\7d\\e9\\1ff2509f13767a55df1279744adfb757f4ab94b2cbe761f56a\n",
      "  Building wheel for free-proxy (setup.py): started\n",
      "  Building wheel for free-proxy (setup.py): finished with status 'done'\n",
      "  Created wheel for free-proxy: filename=free_proxy-1.1.3-py3-none-any.whl size=6212 sha256=584c6e22b39fea0477bad9ff40f16aab5b09a41533cd60839aba8dda02876ae8\n",
      "  Stored in directory: c:\\users\\soumi\\appdata\\local\\pip\\cache\\wheels\\b1\\5b\\61\\c93b717842c89aac55d0590076f64041825eb8d89712fca95a\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6105 sha256=43eff94b86f4d34423302943d4c5de2bd750f3335b8fe944e96081ffaded45d4\n",
      "  Stored in directory: c:\\users\\soumi\\appdata\\local\\pip\\cache\\wheels\\03\\f5\\1a\\23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
      "Successfully built bibtexparser free-proxy sgmllib3k\n",
      "Installing collected packages: sortedcontainers, sgmllib3k, wsproto, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, snowballstemmer, roman-numerals-py, PySocks, outcome, lxml, imagesize, feedparser, fake-useragent, docutils, deprecated, bibtexparser, alabaster, trio, sphinx, free-proxy, arxiv, trio-websocket, sphinxcontrib-jquery, sphinx-rtd-theme, selenium, scholarly\n",
      "\n",
      "   - --------------------------------------  1/30 [sgmllib3k]\n",
      "   -- -------------------------------------  2/30 [wsproto]\n",
      "   --- ----------------------------------  3/30 [sphinxcontrib-serializinghtml]\n",
      "   --- ----------------------------------  3/30 [sphinxcontrib-serializinghtml]\n",
      "   ----- ----------------------------------  4/30 [sphinxcontrib-qthelp]\n",
      "   ------ ---------------------------------  5/30 [sphinxcontrib-jsmath]\n",
      "   -------- -------------------------------  6/30 [sphinxcontrib-htmlhelp]\n",
      "   -------- -------------------------------  6/30 [sphinxcontrib-htmlhelp]\n",
      "   --------- ------------------------------  7/30 [sphinxcontrib-devhelp]\n",
      "   --------- ------------------------------  7/30 [sphinxcontrib-devhelp]\n",
      "   ---------- -----------------------------  8/30 [sphinxcontrib-applehelp]\n",
      "   ---------- -----------------------------  8/30 [sphinxcontrib-applehelp]\n",
      "   ------------ ---------------------------  9/30 [snowballstemmer]\n",
      "   ------------ ---------------------------  9/30 [snowballstemmer]\n",
      "   ------------ ---------------------------  9/30 [snowballstemmer]\n",
      "   ------------ ---------------------------  9/30 [snowballstemmer]\n",
      "   ------------ ---------------------------  9/30 [snowballstemmer]\n",
      "   ------------ ---------------------------  9/30 [snowballstemmer]\n",
      "   ------------ ---------------------------  9/30 [snowballstemmer]\n",
      "   -------------- ------------------------- 11/30 [PySocks]\n",
      "   ---------------- ----------------------- 12/30 [outcome]\n",
      "   ----------------- ---------------------- 13/30 [lxml]\n",
      "   ----------------- ---------------------- 13/30 [lxml]\n",
      "   ----------------- ---------------------- 13/30 [lxml]\n",
      "   ----------------- ---------------------- 13/30 [lxml]\n",
      "   ----------------- ---------------------- 13/30 [lxml]\n",
      "   ------------------ --------------------- 14/30 [imagesize]\n",
      "   -------------------- ------------------- 15/30 [feedparser]\n",
      "   -------------------- ------------------- 15/30 [feedparser]\n",
      "   -------------------- ------------------- 15/30 [feedparser]\n",
      "   -------------------- ------------------- 15/30 [feedparser]\n",
      "   --------------------- ------------------ 16/30 [fake-useragent]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ---------------------- ----------------- 17/30 [docutils]\n",
      "   ------------------------ --------------- 18/30 [deprecated]\n",
      "   ------------------------- -------------- 19/30 [bibtexparser]\n",
      "   -------------------------- ------------- 20/30 [alabaster]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ---------------------------- ----------- 21/30 [trio]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ----------------------------- ---------- 22/30 [sphinx]\n",
      "   ------------------------------ --------- 23/30 [free-proxy]\n",
      "   --------------------------------- ------ 25/30 [trio-websocket]\n",
      "   --------------------------------- ------ 25/30 [trio-websocket]\n",
      "   ------------------------------------ --- 27/30 [sphinx-rtd-theme]\n",
      "   ------------------------------------ --- 27/30 [sphinx-rtd-theme]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   ------------------------------------- -- 28/30 [selenium]\n",
      "   -------------------------------------- - 29/30 [scholarly]\n",
      "   -------------------------------------- - 29/30 [scholarly]\n",
      "   ---------------------------------------- 30/30 [scholarly]\n",
      "\n",
      "Successfully installed PySocks-1.7.1 alabaster-1.0.0 arxiv-2.2.0 bibtexparser-1.4.3 deprecated-1.2.18 docutils-0.21.2 fake-useragent-2.2.0 feedparser-6.0.11 free-proxy-1.1.3 imagesize-1.4.1 lxml-6.0.0 outcome-1.3.0.post0 roman-numerals-py-3.1.0 scholarly-1.7.11 selenium-4.34.2 sgmllib3k-1.0.0 snowballstemmer-3.0.1 sortedcontainers-2.4.0 sphinx-8.2.3 sphinx-rtd-theme-3.0.2 sphinxcontrib-applehelp-2.0.0 sphinxcontrib-devhelp-2.0.0 sphinxcontrib-htmlhelp-2.1.0 sphinxcontrib-jquery-4.1 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-2.0.0 sphinxcontrib-serializinghtml-2.0.0 trio-0.30.0 trio-websocket-0.12.2 wsproto-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soumi\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\fields.py:1093: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'required'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install crewai crewai-tools gradio openai arxiv scholarly beautifulsoup4 requests\n",
    "\n",
    "import os\n",
    "import gradio as gr\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import SerperDevTool, WebsiteSearchTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "import arxiv\n",
    "import scholarly\n",
    "from typing import List, Dict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e70916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1842821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom tools for research\n",
    "class ArxivSearchTool:\n",
    "    def search_papers(self, query: str, max_results: int = 5) -> List[Dict]:\n",
    "        \"\"\"Search for papers on arXiv\"\"\"\n",
    "        search = arxiv.Search(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            sort_by=arxiv.SortCriterion.Relevance\n",
    "        )\n",
    "\n",
    "        papers = []\n",
    "        for result in search.results():\n",
    "            papers.append({\n",
    "                \"title\": result.title,\n",
    "                \"authors\": [author.name for author in result.authors],\n",
    "                \"abstract\": result.summary,\n",
    "                \"url\": result.entry_id,\n",
    "                \"published\": str(result.published)\n",
    "            })\n",
    "        return papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a9337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tools\n",
    "arxiv_tool = ArxivSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "712c3c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Agents\n",
    "topic_explainer = Agent(\n",
    "    role='Topic Explainer',\n",
    "    goal='Explain complex research topics in clear, accessible language and provide comprehensive overviews',\n",
    "    backstory=\"\"\"You are an expert educator with deep knowledge across multiple research domains.\n",
    "    You excel at breaking down complex concepts into understandable explanations while maintaining accuracy.\n",
    "    You understand the importance of providing context and connecting ideas to help researchers grasp new topics quickly.\"\"\",\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "literature_finder = Agent(\n",
    "    role='Literature Finder',\n",
    "    goal='Find and summarize relevant research papers, identifying key contributions and methodologies',\n",
    "    backstory=\"\"\"You are a seasoned research librarian with expertise in academic literature search.\n",
    "    You know how to identify the most relevant and impactful papers in any field. You're skilled at\n",
    "    summarizing papers concisely while capturing their key contributions, methodologies, and findings.\"\"\",\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "gap_analyzer = Agent(\n",
    "    role='Gap Analyzer',\n",
    "    goal='Identify research gaps, unexplored areas, and suggest promising research directions',\n",
    "    backstory=\"\"\"You are a research strategist with years of experience in identifying opportunities\n",
    "    in academic research. You excel at spotting patterns, finding gaps in existing literature,\n",
    "    and proposing innovative research directions that could advance the field.\"\"\",\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfaf76ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tasks(research_topic: str):\n",
    "    explain_topic_task = Task(\n",
    "        description=f\"\"\"Provide a comprehensive explanation of the research topic: {research_topic}\n",
    "        Include:\n",
    "        1. Core concepts and definitions\n",
    "        2. Historical context and evolution\n",
    "        3. Current state of the field\n",
    "        4. Key challenges and open questions\n",
    "        5. Interdisciplinary connections\"\"\",\n",
    "        agent=topic_explainer,\n",
    "        expected_output=\"A detailed explanation of the research topic with all requested components\"\n",
    "    )\n",
    "\n",
    "    find_literature_task = Task(\n",
    "        description=f\"\"\"Search and analyze literature related to: {research_topic}\n",
    "        For each paper found:\n",
    "        1. Provide title, authors, and publication year\n",
    "        2. Summarize the main contributions\n",
    "        3. Explain the methodology used\n",
    "        4. Highlight key findings\n",
    "        5. Note limitations mentioned by authors\n",
    "        Use the arxiv_tool to search for papers.\"\"\",\n",
    "        agent=literature_finder,\n",
    "        expected_output=\"A comprehensive literature review with summaries of relevant papers\"\n",
    "    )\n",
    "\n",
    "    analyze_gaps_task = Task(\n",
    "        description=f\"\"\"Based on the topic explanation and literature review for {research_topic}, identify:\n",
    "        1. Research gaps in the current literature\n",
    "        2. Unexplored or underexplored areas\n",
    "        3. Methodological limitations in existing work\n",
    "        4. Potential interdisciplinary opportunities\n",
    "        5. Suggest 3-5 specific research questions that could address these gaps\n",
    "        6. Provide a research outline for the most promising direction\"\"\",\n",
    "        agent=gap_analyzer,\n",
    "        expected_output=\"A detailed gap analysis with specific research suggestions and an outline\"\n",
    "    )\n",
    "\n",
    "    return [explain_topic_task, find_literature_task, analyze_gaps_task]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0beaf7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_research_crew(research_topic: str):\n",
    "    tasks = create_tasks(research_topic)\n",
    "\n",
    "    crew = Crew(\n",
    "        agents=[topic_explainer, literature_finder, gap_analyzer],\n",
    "        tasks=tasks,\n",
    "        process=Process.sequential,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    return crew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad08c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_research_companion(research_topic: str, specific_focus: str = None):\n",
    "    \"\"\"Run the research companion for a given topic\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37fa0cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_research_companion(research_topic: str, specific_focus: str = None):\n",
    "    \"\"\"Run the research companion for a given topic\"\"\"\n",
    "    # Modify topic if specific focus is provided\n",
    "    if specific_focus and specific_focus.strip():\n",
    "        full_topic = f\"{research_topic} with focus on {specific_focus}\"\n",
    "    else:\n",
    "        full_topic = research_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e01b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradio_interface(research_topic, specific_focus, api_key):\n",
    "    \"\"\"Gradio interface function\"\"\"\n",
    "\n",
    "    # Update API key if provided\n",
    "    if api_key and api_key.strip():\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "    if not research_topic:\n",
    "        return \"Please enter a research topic.\", \"\", \"\", \"\"\n",
    "\n",
    "    # Run the research companion\n",
    "    results = run_research_companion(research_topic, specific_focus)\n",
    "    if \"error\" in results:\n",
    "        error_msg = f\"Error: {results['error']}\"\n",
    "        return error_msg, error_msg, error_msg, error_msg\n",
    "\n",
    "    # Format outputs\n",
    "    explanation = results.get(\"explanation\", results.get(\"full_output\", \"\"))\n",
    "    literature = results.get(\"literature_review\", \"\")\n",
    "    gaps = results.get(\"gap_analysis\", \"\")\n",
    "\n",
    "    # Create formatted output\n",
    "    formatted_output = f\"\"\"\n",
    "# Research Analysis for: {results['topic']}\n",
    "\n",
    "## Topic Explanation\n",
    "{explanation}\n",
    "\n",
    "## Literature Review\n",
    "{literature}\n",
    "\n",
    "## Gap Analysis and Research Suggestions\n",
    "{gaps}\n",
    "\"\"\"\n",
    "\n",
    "    return formatted_output, explanation, literature, gaps\n",
    "\n",
    "# Create Gradio UI\n",
    "with gr.Blocks(title=\"AI Research Paper Companion\") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # 🔬 AI Research Paper Companion\n",
    "\n",
    "    This tool uses AI agents to help you understand research topics, find relevant literature, and identify research gaps.\n",
    "\n",
    "    **Features:**\n",
    "    - **Topic Explainer**: Provides comprehensive explanations of research topics\n",
    "    - **Literature Finder**: Searches and summarizes relevant papers\n",
    "    - **Gap Analyzer**: Identifies research gaps and suggests new directions\n",
    "    \"\"\")\n",
    "\n",
    "    # Continue with the rest of your Gradio interface code...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4efdb9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_research_companion(research_topic, specific_focus=None):\n",
    "    # Combine topic and focus\n",
    "    full_topic = research_topic\n",
    "    if specific_focus:\n",
    "        full_topic += f\" with focus on {specific_focus}\"\n",
    "\n",
    "    # Create and run the crew\n",
    "    crew = create_research_crew(full_topic)\n",
    "\n",
    "    try:\n",
    "        # Execute the crew\n",
    "        result = crew.kickoff()\n",
    "\n",
    "        # Parse results\n",
    "        output = {\n",
    "            \"topic\": full_topic,\n",
    "            \"explanation\": \"\",\n",
    "            \"literature_review\": \"\",\n",
    "            \"gap_analysis\": \"\",\n",
    "            \"full_output\": str(result)\n",
    "        }\n",
    "\n",
    "        # Extract individual agent outputs if available\n",
    "        if hasattr(result, 'tasks_output'):\n",
    "            if len(result.tasks_output) >= 3:\n",
    "                output[\"explanation\"] = str(result.tasks_output[0])\n",
    "                output[\"literature_review\"] = str(result.tasks_output[1])\n",
    "                output[\"gap_analysis\"] = str(result.tasks_output[2])\n",
    "\n",
    "        return output\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": f\"An error occurred: {str(e)}\",\n",
    "            \"topic\": full_topic\n",
    "        }\n",
    "\n",
    "# Gradio Interface\n",
    "def gradio_interface(research_topic, specific_focus, api_key):\n",
    "    \"\"\"Gradio interface function\"\"\"\n",
    "\n",
    "    # Update API key if provided\n",
    "    if api_key and api_key.strip():\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "    if not research_topic:\n",
    "        return \"Please enter a research topic.\", \"\", \"\", \"\"\n",
    "\n",
    "    # Run the research companion\n",
    "    results = run_research_companion(research_topic, specific_focus)\n",
    "    if \"error\" in results:\n",
    "        return f\"Error: {results['error']}\", \"\", \"\", \"\"\n",
    "\n",
    "    # Format outputs\n",
    "    explanation = results.get(\"explanation\", results.get(\"full_output\", \"\"))\n",
    "    literature = results.get(\"literature_review\", \"\")\n",
    "    gaps = results.get(\"gap_analysis\", \"\")\n",
    "\n",
    "    return explanation, literature, gaps, results.get(\"full_output\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32d4ceb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    [Errno 10048] error while attempting to bind on address ('0.0.0.0', 7861): only one usage of each socket address (protocol/network address/port) is normally permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7862\n",
      "* Running on public URL: https://9ea05a16012c9ad148.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9ea05a16012c9ad148.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭──────────────────────────────────────────── Crew Execution Started ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Crew Execution Started</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008080; text-decoration-color: #008080\">crew</span>                                                                                                     <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008080; text-decoration-color: #008080\">67d15860-cc04-409f-97d0-d4b92e7e5089</span>                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m╭─\u001b[0m\u001b[36m───────────────────────────────────────────\u001b[0m\u001b[36m Crew Execution Started \u001b[0m\u001b[36m────────────────────────────────────────────\u001b[0m\u001b[36m─╮\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[1;36mCrew Execution Started\u001b[0m                                                                                         \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[36mcrew\u001b[0m                                                                                                     \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[37mID: \u001b[0m\u001b[36m67d15860-cc04-409f-97d0-d4b92e7e5089\u001b[0m                                                                       \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭─────────────────────────────────────────────── 🤖 Agent Started ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Topic Explainer</span>                                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Provide a comprehensive explanation of the research topic: Machine learning with focus on Reinforcement</span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">learning</span>                                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        Include:</span>                                                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        1. Core concepts and definitions</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        2. Historical context and evolution</span>                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        3. Current state of the field</span>                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        4. Key challenges and open questions</span>                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        5. Interdisciplinary connections</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m╭─\u001b[0m\u001b[35m──────────────────────────────────────────────\u001b[0m\u001b[35m 🤖 Agent Started \u001b[0m\u001b[35m───────────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mTopic Explainer\u001b[0m                                                                                         \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92mProvide a comprehensive explanation of the research topic: Machine learning with focus on Reinforcement\u001b[0m  \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92mlearning\u001b[0m                                                                                                       \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        Include:\u001b[0m                                                                                               \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        1. Core concepts and definitions\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        2. Historical context and evolution\u001b[0m                                                                    \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        3. Current state of the field\u001b[0m                                                                          \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        4. Key challenges and open questions\u001b[0m                                                                   \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        5. Interdisciplinary connections\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45060650a5f486882b2df8dc4cd5ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── ✅ Agent Final Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Topic Explainer</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">1. Core Concepts and Definitions:</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Machine learning is a subset of artificial intelligence that provides systems the ability to learn and </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">improve from experience without being explicitly programmed. Reinforcement learning (RL) is a type of machine</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">learning where an agent learns to behave in an environment by performing certain actions and observing the </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">results. </span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">In RL, an agent makes decisions by following a policy - a mapping of perceived states of the environment to </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">actions to take in those states. The agent receives rewards or penalties (reinforcements) for its actions, </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">aiming to maximize the total reward. The key components of RL include the environment, the agent, the </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">actions, the states, and the rewards.</span>                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">2. Historical Context and Evolution:</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Reinforcement learning has roots in psychology and control theory. The concept was first formalized by </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Richard Bellman in the 1950s. In the 1980s, reinforcement learning began to be studied as a distinct field </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">with the introduction of algorithms like Q-Learning and SARSA. </span>                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The field gained attention in the late 1990s when Gerald Tesauro’s backgammon program, TD-Gammon, achieved </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">competitive performance using RL techniques. The 2010s saw a significant advancement with the development of </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Deep Reinforcement Learning, combining deep learning with RL, as demonstrated by DeepMind's AlphaGo program </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">defeating a world champion Go player in 2016.</span>                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">3. Current State of the Field:</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">RL is currently a highly active research area. It is being used in various domains like robotics, video </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">games, self-driving cars, finance, and healthcare. Deep RL continues to be a significant focus, with research</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trying to make these algorithms more efficient, stable, and easier to use.</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">4. Key Challenges and Open Questions:</span>                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Despite advancements, several challenges persist in RL. Sample efficiency, i.e., the ability to learn </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">effectively from a small amount of data, is a significant issue. The exploration-exploitation trade-off, </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">deciding between trying new actions or sticking with known ones, remains a key challenge. </span>                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The safety and reliability of RL algorithms in real-world settings are also critical concerns. Additionally, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">there are open questions about how to best incorporate prior knowledge into RL algorithms and how to make </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">these algorithms more interpretable and transparent.</span>                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">5. Interdisciplinary Connections:</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">RL intersects with many other fields. In computer science, it links with areas like artificial intelligence, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">operations research, and optimization. In neuroscience, concepts from RL are used to understand decision </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">making and learning in the brain.</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">In economics and game theory, RL techniques are used to model and predict behavior. In robotics, RL is used </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">for training robots to perform complex tasks. The field also has deep connections with statistics and </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">mathematics, particularly in the areas of probability theory and optimization.</span>                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m ✅ Agent Final Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mTopic Explainer\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mFinal Answer:\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m1. Core Concepts and Definitions:\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mMachine learning is a subset of artificial intelligence that provides systems the ability to learn and \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mimprove from experience without being explicitly programmed. Reinforcement learning (RL) is a type of machine\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mlearning where an agent learns to behave in an environment by performing certain actions and observing the \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mresults. \u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mIn RL, an agent makes decisions by following a policy - a mapping of perceived states of the environment to \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mactions to take in those states. The agent receives rewards or penalties (reinforcements) for its actions, \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92maiming to maximize the total reward. The key components of RL include the environment, the agent, the \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mactions, the states, and the rewards.\u001b[0m                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m2. Historical Context and Evolution:\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mReinforcement learning has roots in psychology and control theory. The concept was first formalized by \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mRichard Bellman in the 1950s. In the 1980s, reinforcement learning began to be studied as a distinct field \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mwith the introduction of algorithms like Q-Learning and SARSA. \u001b[0m                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mThe field gained attention in the late 1990s when Gerald Tesauro’s backgammon program, TD-Gammon, achieved \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mcompetitive performance using RL techniques. The 2010s saw a significant advancement with the development of \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mDeep Reinforcement Learning, combining deep learning with RL, as demonstrated by DeepMind's AlphaGo program \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mdefeating a world champion Go player in 2016.\u001b[0m                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m3. Current State of the Field:\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mRL is currently a highly active research area. It is being used in various domains like robotics, video \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mgames, self-driving cars, finance, and healthcare. Deep RL continues to be a significant focus, with research\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mtrying to make these algorithms more efficient, stable, and easier to use.\u001b[0m                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m4. Key Challenges and Open Questions:\u001b[0m                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mDespite advancements, several challenges persist in RL. Sample efficiency, i.e., the ability to learn \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92meffectively from a small amount of data, is a significant issue. The exploration-exploitation trade-off, \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mdeciding between trying new actions or sticking with known ones, remains a key challenge. \u001b[0m                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mThe safety and reliability of RL algorithms in real-world settings are also critical concerns. Additionally, \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mthere are open questions about how to best incorporate prior knowledge into RL algorithms and how to make \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mthese algorithms more interpretable and transparent.\u001b[0m                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m5. Interdisciplinary Connections:\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mRL intersects with many other fields. In computer science, it links with areas like artificial intelligence, \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92moperations research, and optimization. In neuroscience, concepts from RL are used to understand decision \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mmaking and learning in the brain.\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mIn economics and game theory, RL techniques are used to model and predict behavior. In robotics, RL is used \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mfor training robots to perform complex tasks. The field also has deep connections with statistics and \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mmathematics, particularly in the areas of probability theory and optimization.\u001b[0m                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────────────────── Task Completion ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task Completed</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008000; text-decoration-color: #008000\">2e20a568-baca-409b-892c-f2f5e708a0ab</span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Topic Explainer</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m Task Completion \u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;32mTask Completed\u001b[0m                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[32m2e20a568-baca-409b-892c-f2f5e708a0ab\u001b[0m                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[32mTopic Explainer\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭─────────────────────────────────────────────── 🤖 Agent Started ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Literature Finder</span>                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Search and analyze literature related to: Machine learning with focus on Reinforcement learning</span>          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        For each paper found:</span>                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        1. Provide title, authors, and publication year</span>                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        2. Summarize the main contributions</span>                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        3. Explain the methodology used</span>                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        4. Highlight key findings</span>                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        5. Note limitations mentioned by authors</span>                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        Use the arxiv_tool to search for papers.</span>                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m╭─\u001b[0m\u001b[35m──────────────────────────────────────────────\u001b[0m\u001b[35m 🤖 Agent Started \u001b[0m\u001b[35m───────────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mLiterature Finder\u001b[0m                                                                                       \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92mSearch and analyze literature related to: Machine learning with focus on Reinforcement learning\u001b[0m          \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        For each paper found:\u001b[0m                                                                                  \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        1. Provide title, authors, and publication year\u001b[0m                                                        \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        2. Summarize the main contributions\u001b[0m                                                                    \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        3. Explain the methodology used\u001b[0m                                                                        \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        4. Highlight key findings\u001b[0m                                                                              \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        5. Note limitations mentioned by authors\u001b[0m                                                               \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        Use the arxiv_tool to search for papers.\u001b[0m                                                               \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5f80d412ef4a5da05d0af505fb7cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── ✅ Agent Final Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Literature Finder</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">1. Paper: \"Playing Atari with Deep Reinforcement Learning\", Authors: Volodymyr Mnih, Koray Kavukcuoglu, David</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Silver, et al., Published: 2013</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   - Main Contributions: This paper introduced the first successful integration of deep learning with </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reinforcement learning. The authors proposed a model, Deep Q-Network (DQN), that was able to learn successful</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning.</span>                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   </span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   - Methodology: The authors developed a variant of Q-Learning, which uses a deep neural network as a </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">function approximator. The key innovation of DQN was the use of a technique known as Experience Replay that </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">randomizes over the data, removing correlations in the observation sequence and smoothing over changes in the</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">data distribution.</span>                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   </span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   - Key Findings: The proposed model was tested on a range of Atari 2600 games and achieved a level </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">comparable to professional human game testers on three of the games, and surpassed human performance on a </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">few.</span>                                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   </span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   - Limitations: The authors noted that their approach did not perform as well on some games that require </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">long-term strategic planning or have infrequent rewards. The model also required a large amount of data and </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">computational resources.</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">2. Paper: \"Human-level control through deep reinforcement learning\", Authors: Volodymyr Mnih, Koray </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Kavukcuoglu, David Silver, et al., Published: 2015</span>                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   - Main Contributions: In this paper, the authors demonstrated that the deep Q-network (DQN) algorithm is </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">capable of learning successful policies directly from high-dimensional sensory inputs using end-to-end </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reinforcement learning.</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   </span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   - Methodology: The authors used a deep neural network to approximate the optimal action-value function, </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">which is a key component in Q-learning. The network was trained with a variant of Q-learning, using a replay </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">memory for more efficient data use.</span>                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   </span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   - Key Findings: The proposed model was tested on 49 Atari games, where it performed at more than 75% of </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the human score on more than half of the games. It also outperformed all previous approaches on 43 games.</span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   </span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   - Limitations: The authors noted that it was not clear how the approach would perform on tasks that </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">require intricate memory or planning capabilities. They also mentioned that the model could be improved with </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">a more sophisticated policy iteration algorithm.</span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">3. Paper: \"Mastering the game of Go with deep neural networks and tree search\", Authors: David Silver, Aja </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Huang, Chris J. Maddison, et al., Published: 2016</span>                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   - Main Contributions: This paper marked a milestone in AI research. The authors presented AlphaGo, a </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">computer program that combines Monte Carlo tree search with deep neural networks to master the game of Go, a </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">complex board game known for its vast state-space.</span>                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   </span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   - Methodology: AlphaGo uses a value network to evaluate board positions and a policy network to select </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">moves. These networks are trained using a combination of supervised learning from human expert games, and </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reinforcement learning from games AlphaGo plays against itself.</span>                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   </span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   - Key Findings: The AlphaGo program was able to defeat the human world champion, demonstrating the power </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">of combining reinforcement learning with deep learning.</span>                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   </span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   - Limitations: The authors acknowledged that AlphaGo requires a large amount of computational resources </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and training data. They also mentioned that the performance of AlphaGo depends on a good balance between </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">exploration and exploitation, which can be a challenge.</span>                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">These papers represent key developments in the field of Reinforcement Learning. They have contributed to the </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">integration of deep learning with reinforcement learning, resulting in significant advancements in </span>            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">game-playing AI. However, these studies also highlight ongoing challenges in the field, such as the need for </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">large amounts of data and computational resources, and difficulties in tasks requiring long-term planning or </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">infrequent rewards. Furthermore, balancing exploration and exploitation remains an important issue in </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reinforcement learning.</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m ✅ Agent Final Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mLiterature Finder\u001b[0m                                                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mFinal Answer:\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m1. Paper: \"Playing Atari with Deep Reinforcement Learning\", Authors: Volodymyr Mnih, Koray Kavukcuoglu, David\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mSilver, et al., Published: 2013\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   - Main Contributions: This paper introduced the first successful integration of deep learning with \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mreinforcement learning. The authors proposed a model, Deep Q-Network (DQN), that was able to learn successful\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mpolicies directly from high-dimensional sensory inputs using end-to-end reinforcement learning.\u001b[0m                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   \u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   - Methodology: The authors developed a variant of Q-Learning, which uses a deep neural network as a \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mfunction approximator. The key innovation of DQN was the use of a technique known as Experience Replay that \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mrandomizes over the data, removing correlations in the observation sequence and smoothing over changes in the\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mdata distribution.\u001b[0m                                                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   \u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   - Key Findings: The proposed model was tested on a range of Atari 2600 games and achieved a level \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mcomparable to professional human game testers on three of the games, and surpassed human performance on a \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mfew.\u001b[0m                                                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   \u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   - Limitations: The authors noted that their approach did not perform as well on some games that require \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mlong-term strategic planning or have infrequent rewards. The model also required a large amount of data and \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mcomputational resources.\u001b[0m                                                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m2. Paper: \"Human-level control through deep reinforcement learning\", Authors: Volodymyr Mnih, Koray \u001b[0m           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mKavukcuoglu, David Silver, et al., Published: 2015\u001b[0m                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   - Main Contributions: In this paper, the authors demonstrated that the deep Q-network (DQN) algorithm is \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mcapable of learning successful policies directly from high-dimensional sensory inputs using end-to-end \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mreinforcement learning.\u001b[0m                                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   \u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   - Methodology: The authors used a deep neural network to approximate the optimal action-value function, \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mwhich is a key component in Q-learning. The network was trained with a variant of Q-learning, using a replay \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mmemory for more efficient data use.\u001b[0m                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   \u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   - Key Findings: The proposed model was tested on 49 Atari games, where it performed at more than 75% of \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mthe human score on more than half of the games. It also outperformed all previous approaches on 43 games.\u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   \u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   - Limitations: The authors noted that it was not clear how the approach would perform on tasks that \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mrequire intricate memory or planning capabilities. They also mentioned that the model could be improved with \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92ma more sophisticated policy iteration algorithm.\u001b[0m                                                               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m3. Paper: \"Mastering the game of Go with deep neural networks and tree search\", Authors: David Silver, Aja \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mHuang, Chris J. Maddison, et al., Published: 2016\u001b[0m                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   - Main Contributions: This paper marked a milestone in AI research. The authors presented AlphaGo, a \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mcomputer program that combines Monte Carlo tree search with deep neural networks to master the game of Go, a \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mcomplex board game known for its vast state-space.\u001b[0m                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   \u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   - Methodology: AlphaGo uses a value network to evaluate board positions and a policy network to select \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mmoves. These networks are trained using a combination of supervised learning from human expert games, and \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mreinforcement learning from games AlphaGo plays against itself.\u001b[0m                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   \u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   - Key Findings: The AlphaGo program was able to defeat the human world champion, demonstrating the power \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mof combining reinforcement learning with deep learning.\u001b[0m                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   \u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m   - Limitations: The authors acknowledged that AlphaGo requires a large amount of computational resources \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mand training data. They also mentioned that the performance of AlphaGo depends on a good balance between \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mexploration and exploitation, which can be a challenge.\u001b[0m                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mThese papers represent key developments in the field of Reinforcement Learning. They have contributed to the \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mintegration of deep learning with reinforcement learning, resulting in significant advancements in \u001b[0m            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mgame-playing AI. However, these studies also highlight ongoing challenges in the field, such as the need for \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mlarge amounts of data and computational resources, and difficulties in tasks requiring long-term planning or \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92minfrequent rewards. Furthermore, balancing exploration and exploitation remains an important issue in \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mreinforcement learning.\u001b[0m                                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────────────────── Task Completion ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task Completed</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008000; text-decoration-color: #008000\">970a82b8-d58d-4ec2-ad90-e3d793a07886</span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Literature Finder</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m Task Completion \u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;32mTask Completed\u001b[0m                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[32m970a82b8-d58d-4ec2-ad90-e3d793a07886\u001b[0m                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[32mLiterature Finder\u001b[0m                                                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭─────────────────────────────────────────────── 🤖 Agent Started ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Gap Analyzer</span>                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Based on the topic explanation and literature review for Machine learning with focus on Reinforcement </span>   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">learning, identify:</span>                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        1. Research gaps in the current literature</span>                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        2. Unexplored or underexplored areas</span>                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        3. Methodological limitations in existing work</span>                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        4. Potential interdisciplinary opportunities</span>                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        5. Suggest 3-5 specific research questions that could address these gaps</span>                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        6. Provide a research outline for the most promising direction</span>                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m╭─\u001b[0m\u001b[35m──────────────────────────────────────────────\u001b[0m\u001b[35m 🤖 Agent Started \u001b[0m\u001b[35m───────────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mGap Analyzer\u001b[0m                                                                                            \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92mBased on the topic explanation and literature review for Machine learning with focus on Reinforcement \u001b[0m   \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92mlearning, identify:\u001b[0m                                                                                            \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        1. Research gaps in the current literature\u001b[0m                                                             \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        2. Unexplored or underexplored areas\u001b[0m                                                                   \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        3. Methodological limitations in existing work\u001b[0m                                                         \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        4. Potential interdisciplinary opportunities\u001b[0m                                                           \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        5. Suggest 3-5 specific research questions that could address these gaps\u001b[0m                               \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        6. Provide a research outline for the most promising direction\u001b[0m                                         \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ff8403888a47e098747db48d1ed055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── ✅ Agent Final Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Gap Analyzer</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The field of reinforcement learning (RL) presents several research gaps and opportunities. Key gaps include </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the need for data-efficient learning, difficulty in handling tasks with long-term planning or infrequent </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">rewards, and a lack of interpretability and transparency. Underexplored areas include the incorporation of </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">prior knowledge into RL algorithms and their application in real-world scenarios. Current methodologies face </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">limitations such as high computational cost and balancing exploration and exploitation. Interdisciplinary </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">collaboration with fields like psychology, finance, healthcare, statistics, and mathematics could offer </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">innovative approaches and insights.</span>                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Specific research questions that could be pursued include improving RL algorithms' data efficiency, </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">incorporating prior knowledge, designing algorithms for long-term planning tasks, enhancing interpretability </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and transparency, and optimizing the balance between exploration and exploitation. The most promising </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">direction for future research would be to enhance data efficiency in RL algorithms. This could involve </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">developing novel RL algorithms that learn efficiently from small datasets, potentially using meta-learning or</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">transfer learning techniques. Such research would involve comparative studies with existing RL algorithms </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">across various tasks and comprehensive analysis and discussion of the results.</span>                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m ✅ Agent Final Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mGap Analyzer\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mFinal Answer:\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mThe field of reinforcement learning (RL) presents several research gaps and opportunities. Key gaps include \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mthe need for data-efficient learning, difficulty in handling tasks with long-term planning or infrequent \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mrewards, and a lack of interpretability and transparency. Underexplored areas include the incorporation of \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mprior knowledge into RL algorithms and their application in real-world scenarios. Current methodologies face \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mlimitations such as high computational cost and balancing exploration and exploitation. Interdisciplinary \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mcollaboration with fields like psychology, finance, healthcare, statistics, and mathematics could offer \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92minnovative approaches and insights.\u001b[0m                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mSpecific research questions that could be pursued include improving RL algorithms' data efficiency, \u001b[0m           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mincorporating prior knowledge, designing algorithms for long-term planning tasks, enhancing interpretability \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mand transparency, and optimizing the balance between exploration and exploitation. The most promising \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mdirection for future research would be to enhance data efficiency in RL algorithms. This could involve \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mdeveloping novel RL algorithms that learn efficiently from small datasets, potentially using meta-learning or\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mtransfer learning techniques. Such research would involve comparative studies with existing RL algorithms \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92macross various tasks and comprehensive analysis and discussion of the results.\u001b[0m                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────────────────── Task Completion ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task Completed</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008000; text-decoration-color: #008000\">b1afa57e-a822-4379-82ba-6bf39bf305bc</span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Gap Analyzer</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m Task Completion \u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;32mTask Completed\u001b[0m                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[32mb1afa57e-a822-4379-82ba-6bf39bf305bc\u001b[0m                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[32mGap Analyzer\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────────────────── Crew Completion ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Crew Execution Completed</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008000; text-decoration-color: #008000\">crew</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008000; text-decoration-color: #008000\">67d15860-cc04-409f-97d0-d4b92e7e5089</span>                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Output: The field of reinforcement learning (RL) presents several research gaps and opportunities. Key </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">gaps include the need for data-efficient learning, difficulty in handling tasks with long-term planning or </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">infrequent rewards, and a lack of interpretability and transparency. Underexplored areas include the </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">incorporation of prior knowledge into RL algorithms and their application in real-world scenarios. Current </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">methodologies face limitations such as high computational cost and balancing exploration and exploitation. </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Interdisciplinary collaboration with fields like psychology, finance, healthcare, statistics, and mathematics</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">could offer innovative approaches and insights.</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Specific research questions that could be pursued include improving RL algorithms' data efficiency, </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">incorporating prior knowledge, designing algorithms for long-term planning tasks, enhancing interpretability </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">and transparency, and optimizing the balance between exploration and exploitation. The most promising </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">direction for future research would be to enhance data efficiency in RL algorithms. This could involve </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">developing novel RL algorithms that learn efficiently from small datasets, potentially using meta-learning or</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">transfer learning techniques. Such research would involve comparative studies with existing RL algorithms </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">across various tasks and comprehensive analysis and discussion of the results.</span>                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m Crew Completion \u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;32mCrew Execution Completed\u001b[0m                                                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[32mcrew\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mID: \u001b[0m\u001b[32m67d15860-cc04-409f-97d0-d4b92e7e5089\u001b[0m                                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mFinal Output: The field of reinforcement learning (RL) presents several research gaps and opportunities. Key \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mgaps include the need for data-efficient learning, difficulty in handling tasks with long-term planning or \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37minfrequent rewards, and a lack of interpretability and transparency. Underexplored areas include the \u001b[0m          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mincorporation of prior knowledge into RL algorithms and their application in real-world scenarios. Current \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mmethodologies face limitations such as high computational cost and balancing exploration and exploitation. \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mInterdisciplinary collaboration with fields like psychology, finance, healthcare, statistics, and mathematics\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mcould offer innovative approaches and insights.\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mSpecific research questions that could be pursued include improving RL algorithms' data efficiency, \u001b[0m           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mincorporating prior knowledge, designing algorithms for long-term planning tasks, enhancing interpretability \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mand transparency, and optimizing the balance between exploration and exploitation. The most promising \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mdirection for future research would be to enhance data efficiency in RL algorithms. This could involve \u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mdeveloping novel RL algorithms that learn efficiently from small datasets, potentially using meta-learning or\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mtransfer learning techniques. Such research would involve comparative studies with existing RL algorithms \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37macross various tasks and comprehensive analysis and discussion of the results.\u001b[0m                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 0.0.0.0:7861 <> https://f57823b4727d7863b2.gradio.live\n",
      "Killing tunnel 0.0.0.0:7862 <> https://9ea05a16012c9ad148.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# Proxy fix\n",
    "os.environ[\"NO_PROXY\"] = \"localhost,127.0.0.1,::1\"# Complete updated interface\n",
    "def gradio_interface(research_topic, specific_focus, api_key):\n",
    "    if api_key and api_key.strip():\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    \n",
    "    if not research_topic:\n",
    "        return \"Please enter a research topic.\", \"\", \"\", \"\"\n",
    "    \n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        return \"Please provide your OpenAI API key.\", \"\", \"\", \"\"\n",
    "    \n",
    "    results = run_research_companion(research_topic, specific_focus)\n",
    "    \n",
    "    if \"error\" in results:\n",
    "        error_msg = f\"Error: {results['error']}\"\n",
    "        return error_msg, error_msg, error_msg, error_msg\n",
    "    \n",
    "    explanation = results.get(\"explanation\", \"No explanation generated\")\n",
    "    literature = results.get(\"literature_review\", \"No literature review generated\") \n",
    "    gaps = results.get(\"gap_analysis\", \"No gap analysis generated\")\n",
    "    \n",
    "    full_report = f\"\"\"# 🔬 Research Analysis: {results.get('topic', research_topic)}\n",
    "\n",
    "## 📚 Topic Explanation\n",
    "{explanation}\n",
    "\n",
    "## 🔍 Literature Review  \n",
    "{literature}\n",
    "\n",
    "## 🎯 Gap Analysis & Research Suggestions\n",
    "{gaps}\n",
    "\"\"\"\n",
    "    \n",
    "    return explanation, literature, gaps, full_report\n",
    "\n",
    "# Updated Gradio Interface\n",
    "with gr.Blocks(title=\"AI Research Paper Companion\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # 🔬 AI Research Paper Companion\n",
    "    \n",
    "    **Powered by AI Agents:** Topic Explainer | Literature Finder | Gap Analyzer\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            api_key = gr.Textbox(label=\"🔑 OpenAI API Key\", type=\"password\")\n",
    "            topic = gr.Textbox(label=\"🎯 Research Topic\", placeholder=\"e.g., Machine Learning, Quantum Computing\")\n",
    "            focus = gr.Textbox(label=\"🔍 Specific Focus (Optional)\", placeholder=\"e.g., Reinforcement Learning\")\n",
    "            submit = gr.Button(\"🚀 Start Analysis\", variant=\"primary\", size=\"lg\")\n",
    "    \n",
    "    with gr.Tab(\"📊 Agent Results\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"### 📚 Topic Explainer\")\n",
    "                topic_output = gr.Textbox(label=\"\", lines=12, show_label=False)\n",
    "            \n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"### 🔍 Literature Finder\") \n",
    "                literature_output = gr.Textbox(label=\"\", lines=12, show_label=False)\n",
    "            \n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"### 🎯 Gap Analyzer\")\n",
    "                gap_output = gr.Textbox(label=\"\", lines=12, show_label=False)\n",
    "    \n",
    "    with gr.Tab(\"📋 Complete Report\"):\n",
    "        full_output = gr.Markdown(\"\")\n",
    "    \n",
    "    submit.click(\n",
    "        fn=gradio_interface,\n",
    "        inputs=[topic, focus, api_key],\n",
    "        outputs=[topic_output, literature_output, gap_output, full_output]\n",
    "    )\n",
    "\n",
    "# Sabse easy - port parameter hi remove kar do\n",
    "demo.launch(\n",
    "    share=True,\n",
    "    server_name=\"0.0.0.0\", \n",
    "    # server_port=7860,  # Ye line comment kar do\n",
    "    inbrowser=True,\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f382e1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
